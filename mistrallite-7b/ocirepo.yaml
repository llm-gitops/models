apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: OCIRepository
metadata:
  name: mistrallite-7b
  namespace: flux-system
  labels:
    artifact-kind: language-model
  annotations:
    ai.contrib.fluxcd.io/original-model-repo: https://huggingface.co/amazon/MistralLite
    ai.contrib.fluxcd.io/model-repo: TheBloke/MistralLite-7B-GGUF
    ai.contrib.fluxcd.io/model-file: mistrallite.Q5_K_M.gguf
    ai.contrib.fluxcd.io/model-license: apache-2.0
    ai.contrib.fluxcd.io/model-version: v1.0.0
    ai.contrib.fluxcd.io/format: GGUFv2
    ai.contrib.fluxcd.io/family: mistral # backend
    ai.contrib.fluxcd.io/context-size: 16384
    ai.contrib.fluxcd.io/quantization: Q5_K_M
    ai.contrib.fluxcd.io/size-on-disk: 5.13 GB
    ai.contrib.fluxcd.io/memory-required: 7.63 GB
    ai.contrib.fluxcd.io/layers: 32 # which can be offloaded to GPU
    ai.contrib.fluxcd.io/prompt-template: |-
      <|prompter|>{prompt}</s><|assistant|>
spec:
  interval: 10m
  url: oci://ghcr.io/llm-gitops/models/mistrallite-7b-16k
  ref:
    tag: v1.0.0-q5km-gguf
  layerSelector:
    mediaType: "application/vnd.cncf.flux.content.v1.tar+gzip"
    operation: copy
